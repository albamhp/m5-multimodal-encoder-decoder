{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "# Exercise multimodal recognition: RGB-D scene recognition\n",
        "\n",
        "This exercise consists of three parts: two tutorials and the deliverable. The students must modify the code of the tutorial part, and write and discuss the results in the deliverable part that will be used to evaluate the exercise.\n",
        "\n",
        "If you are not familiar with jupyter notebooks please check __[this tutorial](https://jupyter-notebook.readthedocs.io/en/latest/examples/Notebook/What%20is%20the%20Jupyter%20Notebook.html)__ first.\n",
        "\n",
        "# Part 2 (tutorial): RGB-D baseline\n",
        "\n",
        "If you haven followed the tutorial related with single modality, please run **single.ipynb** first for the first part.\n",
        "\n",
        "In this tutorial, you will build a two-branch RGB-D network using PyTorch. The code is loosely based on the __[PyTorch transfer learning tutorial](http://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)__. Just execute the code sequentially, paying attention to the comments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "import copy\n",
        "import itertools\n",
        "import os\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import cuda\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torch.autograd import Variable\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from utils import STD_RGB, STD_DEPTH, MEAN_RGB, MEAN_DEPTH, Compose, CenterCrop, Resize, ToTensor, RandomResizedCrop, \\\n",
        "    RandomHorizontalFlip, Normalize, ImageFolder, imshow_rgb_d\n",
        "\n",
        "plt.ion()  # interactive mode\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "Load Data\n",
        "---------\n",
        "\n",
        "We will use torchvision, torch.utils.data and RGBDutils packages for loading the\n",
        "data. The dataset is structured hierarchically in splits\\modalities\\classes (check the folder)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "pycharm": {}
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name \u0027Compose\u0027 is not defined",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m\u003cipython-input-1-29480b5adedd\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m data_transforms \u003d {\n\u001b[1;32m----\u003e 4\u001b[1;33m     \u0027train\u0027: Compose([\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mRandomResizedCrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m227\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mRandomHorizontalFlip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name \u0027Compose\u0027 is not defined"
          ],
          "output_type": "error"
        }
      ],
      "source": [
        "# Data augmentation and normalization for training\n",
        "\n",
        "data_transforms \u003d {\n",
        "    \u0027train\u0027: Compose([\n",
        "        RandomResizedCrop(227),\n",
        "        RandomHorizontalFlip(),\n",
        "        ToTensor(),\n",
        "        Normalize(MEAN_RGB, STD_RGB, MEAN_DEPTH, STD_DEPTH)]),\n",
        "    \u0027val\u0027: Compose([\n",
        "        Resize(256),\n",
        "        CenterCrop(227),\n",
        "        ToTensor(),\n",
        "        Normalize(MEAN_RGB, STD_RGB, MEAN_DEPTH, STD_DEPTH)]),\n",
        "    \u0027test\u0027: Compose([\n",
        "        Resize(256),\n",
        "        CenterCrop(227),\n",
        "        ToTensor(),\n",
        "        Normalize(MEAN_RGB, STD_RGB, MEAN_DEPTH, STD_DEPTH)]),\n",
        "}\n",
        "\n",
        "# Path to the dataset\n",
        "data_dir \u003d \u0027../datasets/sunrgbd_lite\u0027\n",
        "\n",
        "# Preparing dataset and dataloaders\n",
        "partitions \u003d [\u0027train\u0027, \u0027val\u0027, \u0027test\u0027]\n",
        "image_datasets \u003d {x: ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in partitions}\n",
        "dataloaders \u003d {x: DataLoader(image_datasets[x], batch_size\u003d64, shuffle\u003dTrue, num_workers\u003d4) for x in partitions}\n",
        "dataset_sizes \u003d {x: len(image_datasets[x]) for x in partitions}\n",
        "class_names \u003d image_datasets[\u0027train\u0027].classes\n",
        "\n",
        "use_gpu \u003d cuda.is_available()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "image_datasets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "**Visualize a few samples**\n",
        "\n",
        "Let\u0027s visualize a few RGB-D pairs so as to RGB-D data and data augmentations.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "# Get a batch of training data and visualize the first four pairs\n",
        "inputsRGB, inputsDepth, classes \u003d next(iter(dataloaders[\u0027train\u0027]))\n",
        "inputsRGB, inputsDepth, classes \u003d inputsRGB[0:4], inputsDepth[0:4], classes[0:4]\n",
        "\n",
        "# Make a grid from batch\n",
        "outRGB \u003d torchvision.utils.make_grid(inputsRGB)\n",
        "outDepth \u003d torchvision.utils.make_grid(inputsDepth)\n",
        "\n",
        "imshow_rgb_d(outRGB, outDepth, title\u003d[class_names[x] for x in classes], concat_vert\u003dTrue)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "Training the model\n",
        "------------------\n",
        "\n",
        "Now, let\u0027s write a general function to train a model. Details:\n",
        "\n",
        "-  Uses Adam algorithm for gradient descent.\n",
        "-  Early stoping using best validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs\u003d25):\n",
        "    since \u003d time.time()\n",
        "\n",
        "    best_model_wts \u003d copy.deepcopy(model.state_dict())\n",
        "    best_acc \u003d 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(\u0027Epoch {}/{}\u0027.format(epoch, num_epochs - 1))\n",
        "        print(\u0027-\u0027 * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in [\u0027train\u0027, \u0027val\u0027]:\n",
        "            print(\u0027Phase %s\u0027 % phase)\n",
        "            if phase \u003d\u003d \u0027train\u0027:\n",
        "                if scheduler is not None:\n",
        "                    scheduler.step()\n",
        "                model.train(True)  # Set model to training mode\n",
        "            else:\n",
        "                model.train(False)  # Set model to evaluate mode\n",
        "\n",
        "            running_loss \u003d 0.0\n",
        "            running_corrects \u003d 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for data in dataloaders[phase]:\n",
        "                # get the inputs\n",
        "                inputs_rgb, inputs_hha, labels \u003d data\n",
        "                # wrap them in Variable\n",
        "                if use_gpu:\n",
        "                    inputs_rgb \u003d Variable(inputs_rgb.cuda())\n",
        "                    inputs_hha \u003d Variable(inputs_hha.cuda())\n",
        "                    labels \u003d Variable(labels.cuda())\n",
        "                else:\n",
        "                    inputs_rgb, inputs_hha, labels \u003d Variable(inputs_hha), Variable(inputs_hha), Variable(labels)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                outputs \u003d model((inputs_rgb, inputs_hha))\n",
        "                _, preds \u003d torch.max(outputs.data, 1)\n",
        "\n",
        "                loss \u003d criterion(outputs, labels)\n",
        "\n",
        "                # backward + optimize only if in training phase\n",
        "                if phase \u003d\u003d \u0027train\u0027:\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                # running_loss +\u003d loss.data[0] * inputs_rgb.size(0) # Pytorch 0.4\n",
        "                running_loss +\u003d loss.data.item() * inputs_rgb.size(0)  # Pytorch 1.0\n",
        "                running_corrects +\u003d torch.sum(preds \u003d\u003d labels.data)\n",
        "\n",
        "            epoch_loss \u003d running_loss / dataset_sizes[phase]\n",
        "            epoch_acc \u003d running_corrects.float() / dataset_sizes[phase]\n",
        "\n",
        "            print(\u0027{} Loss: {:.4f} Acc: {:.4f}\u0027.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase \u003d\u003d \u0027val\u0027 and epoch_acc \u003e best_acc:\n",
        "                best_acc \u003d epoch_acc\n",
        "                best_model_wts \u003d copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed \u003d time.time() - since\n",
        "    print(\u0027Training complete in {:.0f}m {:.0f}s\u0027.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print(\u0027Best val Acc: {:4f}\u0027.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "And now, a function to evaluate the model on a particular set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, partition, criterion):\n",
        "    since \u003d time.time()\n",
        "\n",
        "    model.train(False)  # Set model to evaluate mode\n",
        "\n",
        "    running_loss \u003d 0.0\n",
        "    running_corrects \u003d 0\n",
        "\n",
        "    # Iterate over data.\n",
        "    for data in dataloaders[partition]:\n",
        "        # get the inputs\n",
        "        inputs_rgb, inputs_hha, labels \u003d data\n",
        "        # wrap them in Variable\n",
        "        if use_gpu:\n",
        "            inputs_rgb \u003d Variable(inputs_rgb.cuda())\n",
        "            inputs_hha \u003d Variable(inputs_hha.cuda())\n",
        "            labels \u003d Variable(labels.cuda())\n",
        "        else:\n",
        "            inputs_rgb, inputs_hha, labels \u003d Variable(inputs_hha), Variable(inputs_hha), Variable(labels)\n",
        "\n",
        "        # forward\n",
        "        outputs \u003d model((inputs_rgb, inputs_hha))\n",
        "        _, preds \u003d torch.max(outputs.data, 1)\n",
        "        loss \u003d criterion(outputs, labels)\n",
        "\n",
        "        # statistics\n",
        "        # running_loss +\u003d loss.data[0] * inputs_rgb.size(0) # Pytorch 0.4\n",
        "        running_loss +\u003d loss.data.item() * inputs_rgb.size(0)  # Pytorch 1.0\n",
        "        running_corrects +\u003d torch.sum(preds \u003d\u003d labels.data)\n",
        "\n",
        "    test_loss \u003d running_loss / dataset_sizes[partition]\n",
        "    test_acc \u003d running_corrects.item() / dataset_sizes[partition]\n",
        "\n",
        "    print()\n",
        "\n",
        "    time_elapsed \u003d time.time() - since\n",
        "    print(\u0027Tested in {:.0f}m {:.0f}s Loss: {:.4f} Acc: {:.4f}\u0027.format(\n",
        "        time_elapsed // 60, time_elapsed % 60, test_loss, test_acc))\n",
        "\n",
        "    return test_acc, test_loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "Building the RGB-D model\n",
        "----------------------\n",
        "\n",
        "The architecture of the network is shown in the following figure:\n",
        "\u003cimg src\u003d\"figures/rgbd_network.png\" /\u003e\n",
        "\n",
        "The following code creates the RGB-D network by instantiating two AlexNets, that are combined using concatenation just before the classifier. There are some tricky steps due to the way the pretrained AlexNet is implemented in PyTorch. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": "# In PyTorch every network is implementd as a nn.Module\nclass RGBDnet(nn.Module):\n    # The parameters are initialized in __init__(self, ...)\n    def __init__(self, num_classes):\n        super(RGBDnet, self).__init__()\n\n        # RGB branch\n        model_rgb \u003d torchvision.models.densenet121(pretrained\u003dTrue)\n        for param in model_rgb.parameters():\n            param.requires_grad \u003d False\n        \n        # Parameters of newly constructed modules have requires_grad\u003dTrue by default\n        num_ftrs \u003d model_rgb.fc.in_features\n        model_rgb.fc \u003d nn.Linear(num_ftrs, num_ftrs)\n\n        # HHA branch\n        model_hha \u003d torchvision.models.densenet121(pretrained\u003dTrue)\n        for param in model_hha.parameters():\n            param.requires_grad \u003d False\n        \n        # Parameters of newly constructed modules have requires_grad\u003dTrue by default\n        num_ftrs \u003d model_hha.fc.in_features\n        model_hha.fc \u003d nn.Linear(num_ftrs, num_ftrs)\n\n        # Classifier\n        self.classifier \u003d nn.Linear(2 * num_ftrs, num_classes)\n\n    # The data flow is defined in forward. No need to specify backward operations (PyTorch takes care of them)\n    def forward(self, x):\n        x_rgb \u003d self.model_rgb(x[0])\n        x_hha \u003d self.model_hha(x[1])\n        x \u003d torch.cat((x_rgb, x_hha), 1)\n        x \u003d self.classifier(x)\n        return x\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "# Instantiate the model\n",
        "num_classes \u003d len(class_names)\n",
        "model \u003d RGBDnet(num_classes\u003dnum_classes)\n",
        "\n",
        "# You can visualize the resulting network\n",
        "print(model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "Set up the training/fine tuning parameters\n",
        "----------------------\n",
        "\n",
        "The following code creates the optimization criterio and set per-layer training rates to better control the fine tuning and training process. We use a very simple model in which all layers are frozen except the last fully connected one, i.e. the classifier, so it should be easy to improve the performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "# Here we define the learning rate\n",
        "for param in model.parameters():  # Freeze all parameters by default\n",
        "    param.requires_grad \u003d False\n",
        "\n",
        "if use_gpu:\n",
        "    model \u003d model.cuda()\n",
        "\n",
        "criterion \u003d nn.CrossEntropyLoss()\n",
        "\n",
        "learning_rate \u003d 0.001\n",
        "\n",
        "optimizer \u003d Adam(model.parameters(), lr\u003dlearning_rate)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "Train and evaluate the model\n",
        "-----------------\n",
        "\n",
        "It shouldn\u0027t take more than 2 mins to train with the GPU in the server."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "# Train\n",
        "model \u003d train_model(model, criterion, optimizer, None, num_epochs\u003d25)\n",
        "\n",
        "# Evaluate\n",
        "train_acc, _ \u003d evaluate_model(model, \u0027train\u0027, criterion)\n",
        "val_acc, _ \u003d evaluate_model(model, \u0027val\u0027, criterion)\n",
        "test_acc, _ \u003d evaluate_model(model, \u0027test\u0027, criterion)\n",
        "print(\u0027Accuracy. Train: %1.2f%% val: %1.2f%% test: %1.2f%%\u0027 %\n",
        "      (train_acc * 100, val_acc * 100, test_acc * 100))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "# Part 2 (deliverable)\n",
        "\n",
        "This part will be evaluated as deliverable. Please check you include the required results and information. In principle I don\u0027t intent to run your code, just check your numbers and descriptions.\n",
        "\n",
        "* Comparison of RGB, HHA and RGB-D baselines. Include a table with the train, validation and test average accuracies (and standard deviations) over 5 runs for each case (RGB only, HHA only and RGB-D).\n",
        "* Description of the improvements of the RGB-D network, experimental results and discussion (0.25 points)\n",
        "* Team work: description of the contribution of each member of the team.\n",
        "\n",
        "The maximum of the exercise is 0.5 points.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}